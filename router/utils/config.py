model_size = {
    "Deepseek-v3.2-Exp-temp-0-chat": 685,
    "Deepseek-v3.2-Exp-temp-0-reasoner": 685,
    "GPT-4o-mini-temp-0": 8,
    "o4-mini-temp-1": 0,
    "Qwen3-0.6B-temp-0-en-thinking": 0.6,
    "Qwen3-0.6B-temp-0-no-thinking": 0.6,
    "Qwen3-14B-temp-0-en-thinking": 14,
    "Qwen3-14B-temp-0-no-thinking": 14,
}